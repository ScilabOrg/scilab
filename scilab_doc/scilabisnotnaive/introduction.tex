% Copyright (C) 2008-2010 - Consortium Scilab - Digiteo - Michael Baudin
%
% This file must be used under the terms of the 
% Creative Commons Attribution-ShareAlike 3.0 Unported License :
% http://creativecommons.org/licenses/by-sa/3.0/

\section{Introduction}

As a practical example of the problem considered in this
document, consider the following numerical experiments. 
The following session is an example of 
a Scilab session, where we compute the real number 0.1 by two different, 
but mathematically equivalent ways.
\lstset{language=scilabscript}
\begin{lstlisting}
-->format(25)
-->0.1
 ans  =
    0.1000000000000000055511  
-->1.0-0.9
 ans  =
    0.0999999999999999777955  
-->0.1 == 1.0 - 0.9
 ans  =
  F  
\end{lstlisting}

I guess that for a person who has never heard of these problems,
this experiment may be a shock. To get things clearer, let's 
check that the sinus function is also approximated in the sense that 
the value of $sin(\pi)$ is \emph{not exactly} zero.
\lstset{language=scilabscript}
\begin{lstlisting}
-->format(25)
-->sin(0.0)
 ans  =
    0.  
-->sin(%pi)
 ans  =
    0.0000000000000001224647  
\end{lstlisting}

\index{floating point numbers}
With symbolic computation systems, such as Maple\cite{WWWMapleSoft}, 
Mathematica\cite{WWWMathematica} or Maxima\cite{WWWMaxima} for example, 
the calculations are performed with abstract mathematical 
symbols. Therefore, there is no loss of accuracy, as long as 
no numerical evaluation is performed. If a numerical solution is 
required as a rational number of the form $p/q$ where $p$ and $q$ are 
integers and $q\neq 0$, there is still no loss of accuracy.
On the other hand, in numerical computing systems, such as 
Scilab\cite{WWWScilab}, Matlab\cite{WWWMatlab} or Octave\cite{WWWOctave} for example, 
the computations are performed with floating point numbers.
When a numerical value is stored, it is generally associated with a 
rounding error. 

The difficulty of numerical computations is generated by the fact that, while 
the mathematics treat with \emph{real} numbers, the 
computer deals with their \emph{floating point representations}.
This is the difference between the 
\emph{naive}, mathematical, approach, and the \emph{numerical},
floating-point, implementation.

In this article, we will not present the floating point arithmetic in 
detail. Instead, we will show examples of floating point issues by 
using the following algebraic and experimental approach.
\begin{enumerate}
\item First, we will derive the basic theory of a mathematical formula. 
\item Then, we will implement it in Scilab and compare with the 
result given by the equivalent function provided by Scilab.
As we will see, some particular cases do not work well
with our formula, while the Scilab function computes a correct
result.
\item Finally, we will analyze the \emph{reasons} of the differences.
\end{enumerate}
Our numerical experiments will be based on Scilab.

\index{relative error}
\index{absolute error}
In order to measure the accuracy of the results, we will use 
two different measures of error: the relative error and the 
absolute error\cite{Higham:2002:ASN}. 
Assume that $x_c\in\RR$ is a computed value and 
$x_e\in\RR$ is the expected (exact) value. We are looking for 
a measure of the \emph{difference} between these two real numbers. 
Most of the time, we use the relative error 
\begin{eqnarray}
e_r=\frac{|x_c-x_e|}{|x_e|},
\end{eqnarray}
where we assume that $x_e\neq 0$. The relative error $e_r$ is linked with the number of significant 
digits in the computed value $x_c$. For example, if the relative 
error $e_r=10^{-6}$, then the number of significant digits is 6.

When the expected value is zero, the relative error cannot 
be computed, and we then use instead the absolute error  
\begin{eqnarray}
e_a=|x_c-x_e|.
\end{eqnarray}

A practical way of checking the expected result of a computation
is to compare the formula computed "by hand" with the result 
produced by a symbolic tool. Recently, Wolfram has launched the 
\url{http://www.wolframalpha.com}
website which let us access to Mathematica with a classical web browser.
Many examples in this document have been validated with this tool.

\index{IEEE 754}
In the following, we make a brief overview of floating point numbers used in Scilab.
Real variables in Scilab are stored in 
\emph{double precision} floating point variables. Indeed, Scilab uses the IEEE 754 standard so that real 
variables are stored with 64 bits floating point numbers, called \emph{doubles}.
The floating point number associated with a given $x\in\RR$ will be 
denoted by $fl(x)$.

While the real numbers form a continuum, floating point numbers 
are both finite and bounded. Not all real numbers can be represented by a floating point number.
Indeed, there is a infinite number of reals, while there is a finite 
number of floating point numbers. 
In fact, there are, at most, $2^{64}$ different 64 bits floating point numbers. 
This leads to \emph{roundoff}, \emph{underflow} and \emph{overflow}.

The double floating point numbers are associated with a machine epsilon equal to $2^{-52}$,
which is approximately equal to $10^{-16}$. This parameter is 
stored in the \scivar{\%eps} Scilab variable. Therefore, we can expect, at best, 
approximately 16 significant decimal digits. 
This parameter does not depend on the machine we use. Indeed, be it a Linux or a Windows system,
Scilab uses IEEE doubles. Therefore, the value of the \scivar{\%eps} variable is always the same
in Scilab.

Negative normalized floating point numbers are in the 
range $[-10^{308},-10^{-307}]$ and positive normalized floating point numbers are in the 
range $[10^{-307},10^{308}]$. The limits given in the previous intervals 
are only decimal approximations. Any real number greater than $10^{309}$
or smaller than $-10^{309}$ is not representable as a double and is stored with the 
"infinite" value: in this case, we say that an overflow occurred. 
A real which magnitude is smaller than $10^{-324}$ is not representable as a 
double and is stored as a zero: in this case, we say that an underflow occurred.

The outline of this paper is the following. In the first section,
we compute the roots of a quadratic equation. In the second section,
we compute the numerical derivatives of a function. In the final section,
we perform a numerically difficult division, with complex numbers.
The examples presented in this introduction are presented in the 
appendix of this document.


