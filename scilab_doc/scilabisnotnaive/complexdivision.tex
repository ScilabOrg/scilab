% Scilab ( http://www.scilab.org/ ) - This file is part of Scilab
% Copyright (C) 2008-2010 - Digiteo - Michael Baudin
%
% This file must be used under the terms of the CeCILL.
% This source file is licensed as described in the file COPYING, which
% you should have received as part of this distribution.  The terms
% are also available at
% http://www.cecill.info/licences/Licence_CeCILL_V2-en.txt

\section{Complex division}

In this section, we analyze the problem of the complex division in Scilab.
We especially detail the difference between the mathematical, straightforward
formula and the floating point implementation. In the first part, we briefly report 
the formulas which allow to 
compute the real and imaginary parts of the division of two complex numbers.
We then present the naive algorithm based on these mathematical formulas. 
In the second part, we make some experiments in Scilab and compare our
naive algorithm with Scilab's division operator.
In the third part, we analyze 
why and how floating point numbers must be taken into account when the 
implementation of such division is required.

\subsection{Theory}

Assume that $a,b,c$ and $d$ are four real numbers.
Consider the two complex numbers $a + ib$ and $c + id$, where $i$ is 
the imaginary number which satisfies $i^2=-1$. Assume that $c^2 + d^2$ is non zero.
We are interested in the complex number $e+fi = \frac{a + ib}{c + id}$ where $e$ and $f$ are real
numbers.
The formula which allows to compute the real and imaginary parts 
of the division of these two complex numbers is 
\begin{eqnarray}
\label{compdiv-eq-defcomplexdiv}
\frac{a + ib}{c + id} = \frac{ac + bd}{c^2 + d^2} + i \frac{bc - ad}{c^2 + d^2} .
\end{eqnarray}
So that the real and imaginary parts $e$ and $f$ of the complex number are
\begin{eqnarray}
\label{compdiv-eq-e}
e &=& \frac{ac + bd}{c^2 + d^2}, \\
\label{compdiv-eq-f}
f &=& \frac{bc - ad}{c^2 + d^2}.
\end{eqnarray}

The naive algorithm for the computation of the complex division
is presented in figure \ref{naive-complexdivision}.

\begin{algorithm}[htbp]
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
\Input{$a,b,c,d$}
\Output{$e,f$}
$den := c^2 + d^2$\;
$e := (ac + bd)/ den$\;
$f := (bc - ad)/ den$\;
\caption{Naive algorithm to compute the complex division. The algorithm takes as input the 
real and imaginary parts $a,b,c,d$ of the two complex numbers and returns 
$e$ and $f$, the real and imaginary parts of the division.}
\label{naive-complexdivision}
\end{algorithm}

\subsection{Experiments}

The following Scilab function \scifun{naive} is a straightforward implementation
of the previous formulas. It takes as input the complex numbers $a$ and $b$, 
represented by their real and imaginary parts \scivar{a}, \scivar{b}, \scivar{c} and 
\scivar{d}. The function \scifun{naive} returns the complex number represented 
by its real and imaginary parts \scivar{e} and \scivar{f}.
\lstset{language=scilabscript}
\begin{lstlisting}
function [e,f] = naive (a , b , c , d )
  den = c * c + d * d;
  e = (a * c + b * d) / den;
  f = (b * c - a * d) / den;
endfunction
\end{lstlisting}

Consider the complex division
\begin{eqnarray}
\label{eq-cd-firstest}
\frac{1 + i2}{3 + i4} = \frac{11}{25}+i \frac{2}{25}= 0.44 +i 0.08 .
\end{eqnarray}
We check our result with Wolfram Alpha\cite{WWWWolframAlpha}, with 
the input "(1+i*2)/(3+i*4)".
In the following script, we check that there is no obvious bug 
in the naive implementation.
\lstset{language=scilabscript}
\begin{lstlisting}
-->  [e f] = naive ( 1.0 , 2.0 , 3.0 , 4.0 )
 f  =
    0.08  
 e  =
    0.44  
-->  (1.0 + %i * 2.0 )/(3.0 + %i * 4.0 )
 ans  =
    0.44 + 0.08i  
\end{lstlisting}
The results of the \scifun{naive} function and the division operator are the same,
which makes us confident that our implementation is correct.

Now that we are confident, we make the following numerical experiment involving 
a large number. Consider the complex division 
\begin{eqnarray}
\label{eq-cd-10307}
\frac{1 + i}{1 + i 10^{307}  } \approx 1.0000000000000000\cdot 10^{-307} - i 1.0000000000000000\cdot 10^{-307} ,
\end{eqnarray}
which is accurate to the displayed digits. 
We check our result with Wolfram Alpha\cite{WWWWolframAlpha}, with 
the input "(1 + i)/(1 + i * 10$\hat{\;}$307)".
In fact, there are more that 300 zeros following the leading 
1, so that the previous approximation is very accurate.
The following Scilab session compares the naive implementation and Scilab's division operator.
\lstset{language=scilabscript}
\begin{lstlisting}
-->  [e f] = naive ( 1.0 , 1.0 , 1.0 , 1.e307 )
 f  =
    0.  
 e  =
    0.  
-->  (1.0 + %i * 1.0)/(1.0 + %i * 1.e307)
 ans  =
    1.000-307 - 1.000-307i  
\end{lstlisting}
In the previous case, the naive implementation does not produce any correct digit!

The last test involves small numbers in the denominator of the complex fraction.
Consider the complex division 
\begin{eqnarray}
\label{eq-cd-thirdtest}
\frac{1 + i}{10^{-307} +  i 10^{-307} }= \frac{1 + i}{10^{-307}(1 +  i)} = 10^{307}.
\end{eqnarray}
In the following session, the first statement \scifun{ieee(2)} configures the 
IEEE system so that Inf and Nan numbers are generated instead 
of Scilab error messages. 
\lstset{language=scilabscript}
\begin{lstlisting}
-->ieee(2);
-->[e f] = naive ( 1.0 , 1.0 , 1.e-307 , 1.e-307 )
 f  =
   Nan  
 e  =
   Inf  
-->(1.0 + %i * 1.0)/(1.e-307 + %i * 1.e-307)
 ans  =
    1.000+307  
\end{lstlisting}
We see that the naive implementation generates the IEEE numbers Nan and Inf, while the 
division operator produces the correct result.

\subsection{Explanations}

In this section, we analyze the reason why the naive implementation
of the complex division leads to inaccurate results.
In the first section, we perform algebraic computations 
and shows the problems of the naive formulas.
In the second section, we present the Smith's method.

\subsubsection{Algebraic computations}

In this section, we analyze the results produced by the second and third tests in the 
previous numerical experiments. We show that the intermediate numbers which appear
are not representable as double precision floating point numbers.

Let us analyze the second complex division \ref{eq-cd-10307}.
We are going to see that this division is associated with 
an IEEE overflow.
We have $a=1$, $b=1$, $c=1$ and $d=10^{307}$.
By the equations \ref{compdiv-eq-e} and \ref{compdiv-eq-f}, we have 
\begin{eqnarray}
den &=& c^2 + d^2 = 1^2 + (10^{307})^2 \\
  &=& 1 + 10^{614} \approx 10^{614}, \\
e &=& (ac + bd)/ den = (1*1 + 1*10^{307})/10^{614}, \\
  &\approx& 10^{307}/10^{614}  \approx 10^{-307},\\
f &=& (bc - ad)/ den = (1*1 - 1*10^{307})/10^{614} \\
  &\approx& -10^{307}/10^{614} \approx -10^{-307}.
\end{eqnarray}
We see that both the input numbers $a,b,c,d$ are representable 
and the output numbers $e=10^{-307}$ and $f=-10^{-307}$ are representable as double precision
floating point numbers.
We now focus on the floating point representation of the intermediate expressions.
We have 
\begin{eqnarray}
fl(den) = fl(10^{614}) = Inf,
\end{eqnarray}
because $10^{614}$ is not representable as a double precision number. 
Indeed, the largest positive double is $10^{308}$.
The IEEE Inf floating point number stands for Infinity and is associated with an overflow. 
The Inf floating point number is associated with an algebra which defines that $1/Inf = 0$. 
This is consistent with mathematical limit of the function $1/x$ when $x\rightarrow \infty$.
Then, the $e$ and $f$ terms are computed as 
\begin{eqnarray}
fl(e) &=& fl((ac + bd)/ den) = fl((1*1 + 1*10^{307})/Inf) = fl(10^{307}/Inf) = 0,\\
fl(f) &=& fl((bc - ad)/ den) = fl((1*1 - 1*10^{307})/Inf) = fl(-10^{307}/Inf) = 0.
\end{eqnarray}
Hence, the result is computed without any significant digit,
even though both the input and the output numbers are all representable as double precision
floating point numbers.

Let us analyze the second complex division \ref{eq-cd-thirdtest}.
We are going to see that this division is associated with 
an IEEE underflow.
We have $a=1$, $b=1$, $c=10^{-307}$ and $d=10^{-307}$.
We now use the equations \ref{compdiv-eq-e} and \ref{compdiv-eq-f}, which leads to:
\begin{eqnarray}
den &=& c^2 + d^2 = (10^{-307})^2 + (10^{-307})^2 \\
  &=& 10^{-614} + 10^{-614} = 2 . 10^{-616}, \\
e &=& (ac + bd)/ den = (1*10^{-307} + 1*10^{-307})/(2 . 10^{-614}) \\
 &=&  (2 . 10^{-307})/(2 . 10^{-614}) = 10^{307}, \\
f &=& (bc - ad)/ den = (1*10^{-307} - 1*10^{-307})/(2 . 10^{-614}) \\
  &=& 0/10^{-614} = 0.
\end{eqnarray}
With double precision floating point numbers, the computation is not performed this way.
The positive terms which are smaller than $10^{-324}$ are too small to be representable 
in double precision and are represented by 0 so that an underflow occurs.
This leads to
\begin{eqnarray}
fl(den) &=& fl(c^2 + d^2) = fl(10^{-614} + 10^{-614}) \\
&=& 0, \\
fl(e) &=& fl((ac + bd)/ den) = fl((1*10^{-307} + 1*10^{-307})/(2 . 10^{-614}))  \\
&=& fl( 2. 10^{-307}/0 ) = Inf, \\
fl(f) &=& fl((bc - ad)/ den) = fl((1*10^{-307} - 1*10^{-307})/0)  \\
&=& fl(0/0) = NaN.
\end{eqnarray}

The two previous examples shows that, even if both the input and output numbers are 
representable as floating point numbers, the intermediate expressions 
may generate numbers which may not be representable as floating point 
numbers. Hence, a naive implementation can lead to inaccurate results.
In the next section, we present a method which allows to cure most 
problems generated by the complex division.

\subsubsection{Smith's method}

In this section, we analyze Smith's method, which allows to produce an accurate 
division of two complex numbers. We present the detailed steps of this modified 
algorithm in the particular cases that we have presented.

\index{Smith, Robert}
In Scilab, the algorithm which allows to perform the complex 
division is done by the the \emph{wwdiv} routine, which implements  
Smith's method \cite{Smith1962}.
This implementation is due to Bruno Pin{\c c}on.
Smith's algorithm is based on normalization, which allow to 
perform the complex division even if the input terms are large or small. 

The starting point of the method is the mathematical definition \ref{compdiv-eq-defcomplexdiv},
which is reproduced here for simplicity
\begin{eqnarray}
\label{compdiv-eq-defcomplexdiv2}
\frac{a + ib}{c + id} = e+if = \frac{ac + bd}{c^2 + d^2} + i \frac{bc - ad}{c^2 + d^2}.
\end{eqnarray}

Smith's method is based on the rewriting of this formula in 
two different, but mathematically equivalent, formulas. 
We have seen that the term $c^2 + d^2$ may generate overflows or underflows.
This is caused by intermediate expressions which magnitudes are larger than necessary.
The previous numerical experiments suggest that, provided that we 
had simplified the calculation, the intermediate expressions 
would not have been unnecessary large. 

Consider the term $e=\frac{ac + bd}{c^2 + d^2}$ in the equation \ref{compdiv-eq-defcomplexdiv2}
and assume that $c\neq 0$ and $d\neq0$.
Let us assume that $c$ is large in magnitude with respect to $d$, i.e. $|d|\ll|c|$. 
This implies $d/c \leq 1$. We see that the denominator $c^2 + d^2$ 
squares the number $c$, which also appears in the numerator. Therefore, 
we multiply both the numerator and the denominator by $1/c$. If we  
express $e$ as $\frac{a + b(d/c)}{c + d (d/c)}$, which is 
mathematically equivalent, we see that there is no more squaring of $c$.
Hence, overflows are less likely to occur in the denominator, since $|d (d/c)|= |d| |d/c| \leq |d|$.
That is, there is no growth in the magnitude of the terms involved in the 
computation of the product $d(d/c)$.
Similarly, overflows are less likely to occur in the numerator, since 
$|b(d/c)|= |b| |d/c| \leq |b|$. In the opposite case where $d$ is large with 
respect to $c$, i.e. $d\gg c$, we could divide the numerator and the denominator by $1/d$.
This leads to the formulas
\begin{eqnarray}
\frac{a + ib}{c + id} 
&=& \frac{a + b(d/c)}{c + d(d/c)} + i \frac{b - a(d/c)}{c + d(d/c)}, \\
&=& \frac{a(c/d) + b}{c(c/d) + d} + i \frac{b(c/d) - a}{c(c/d) + d}. 
\end{eqnarray}

The previous equations can be simplified as 
\begin{eqnarray}
\frac{a + ib}{c + id} 
&=& \frac{a + br}{c + dr} + i \frac{b - ar}{c + dr} , \qquad r = d/c, \textrm{ if } c\geq d,\\
&=& \frac{ar + b}{cr + d} + i \frac{br - a}{cr + d}, \qquad r = c/d, \textrm{ if } d\geq c.
\end{eqnarray}

The following \scifun{smith} function implements 
Smith's method in the Scilab language.
\lstset{language=scilabscript}
\begin{lstlisting}
function [e,f] = smith ( a , b , c , d )
  if ( abs(d) <= abs(c) ) then
    r = d/c;
    den = c + d * r;
    e = (a + b * r) / den;
    f = (b - a * r) / den;
  else
    r = c/d;
    den = c * r + d;
    e = (a * r + b) / den;
    f = (b * r - a) / den;
  end
endfunction
\end{lstlisting}

We now check that Smith's method performs very well for the difficult complex 
division that we met earlier in this chapter.

Let us analyze the second complex division \ref{eq-cd-10307}.
We have $a=1$, $b=1$, $c=1$ and $d=10^{307}$.
For this division, Smith's method is the following.
\begin{lstlisting}
if ( |1.e307| <= |1| ) > test false
else
  r = c/d = 1 / 1.e307 = 1.e-307
  den  = c * r + d = 1 * 1.e-307 + 1.e307 = 1.e307
  e = (a * r + b)/den = (1 * 1.e-307 + 1) / 1.e307 = 1 / 1.e307 
    = 1.e-307
  f = (b * r - a)/den = (1 * 1.e-307 - 1) / 1.e307 = -1 / 1.e307 
    = -1.e-308
\end{lstlisting}
We see that, while the naive division generated an overflow, Smith's 
method produces the correct result.

Let us analyze the second complex division \ref{eq-cd-thirdtest}.
We have $a=1$, $b=1$, $c=10^{-307}$ and $d=10^{-307}$.
\begin{lstlisting}
if ( |1.e-307| <= |1.e-307| ) > test true
  r = d/c = 1.e-307 / 1.e-307 = 1
  den  = c + d * r = 1.e-307 +  1e-307 * 1 = 2.e-307
  e = (a + b * r) / den = (1 + 1 * 1) / 2.e-307 = 2/2.e-307 
    = 1.e307
  f = (b - a * r) / den = (1 - 1 * 1) / 2.e-307 
    = 0
\end{lstlisting}
We see that, while the naive division generated an underflow, Smith's 
method produces the correct result.

Now that we have designed a more robust algorithm, we are interested in 
testing Smith's method on a more difficult case.

\subsection{One more step}

In this section, we show the limitations of Smith's method
and present an example where Smith's method does not perform as 
expected.

The following example is inspired by an example by Stewart's in \cite{214414}. 
While Stewart gives an example based on a machine with an exponent range 
$\pm 99$, we consider an example which is based on Scilab's doubles. 
Consider the complex division
\begin{eqnarray}
\frac{10^{307} +  i 10^{-307}}{10^{204} +   i 10^{-204}} 
\approx 1.000000000000000 \cdot 10^{103} -  i 1.000000000000000 \cdot 10^{-305},
\end{eqnarray}
which is accurate to the displayed digits. In fact, there are more that 100 zeros following the leading 
1, so that the previous approximation is very accurate.
The following Scilab session compares the naive implementation, Smith's method
and Scilab's division operator.
The session is performed with Scilab v5.2.0 under a 32 bits Windows
using a Intel Xeon processor.
\lstset{language=scilabscript}
\begin{lstlisting}
-->[e f] = naive ( 1.e307 , 1.e-307 , 1.e204 , 1.e-204 )
 f  =
    0.  
 e  =
   Nan  
-->[e f] = smith ( 1.e307 , 1.e-307 , 1.e204 , 1.e-204 )
 f  =
    0.  
 e  =
    1.000+103  
-->(1.e307 + %i * 1.e-307)/(1.e204 + %i * 1.e-204)
 ans  =
    1.000+103 - 1.000-305i  
\end{lstlisting}
In the previous case, the naive implementation does not produce any correct digit, as 
expected. Smith's method, produces a correct real part, but an inaccurate imaginary 
part. Once again, Scilab's division operator provides the correct 
answer.

We first check why the naive implementation is not accurate in this case.
We have $a=10^{307}$, $b=10^{-307}$, $c=10^{204}$ and $d=10^{-204}$.
Indeed, the naive implementation performs the following steps.
\begin{lstlisting}
  den = c * c + d * d = 1.e204 * 1.e204 + 1.e-204 * 1.e-204 
      = Inf
  e = (a * c + b * d) / den 
    = (1.e307 * 1.e204 + 1.e-307 * 1.e-204 ) / Inf = Inf / Inf 
    = Nan
  f = (b * c - a * d) / den 
    = (1.e-307 * 1.e204 - 1.e307 * 1.e-204) / Inf = -1.e103 / Inf 
    = 0
\end{lstlisting}
We see that the denominator \scivar{den} is in overflow, which 
makes \scivar{e} to be computed as \scivar{Nan} and \scivar{f} 
to be computed as \scivar{0}.

Second, we check that Smith's formula is not accurate in this 
case. Indeed, it performs the following steps.
\begin{lstlisting}
if ( abs(d) = 1.e-204 <= abs(c) = 1.e204 ) > test true
  r = d/c = 1.e-204 / 1.e204 = 0
  den  = c + d * r = 1.e204 +  0 * 1.e-204 = 1.e204
  e = (a + b * r) / den = (1.e307 + 1.e-307 * 0) / 1e204 
    = 1.e307 / 1.e204 = 1.e103
  f = (b - a * r) / den = (1.e-307 - 1.e307 * 0) / 1e204 
    = 1.e-307 / 1.e204 = 0
\end{lstlisting}
We see that the variable \scivar{r} is in underflow, so that it is 
represented by zero. This simplifies the denominator \scivar{den},
but this variable is still correctly computed, because it is dominated 
the term \scivar{c}. The real part \scivar{e} is still accurate, because,
once again, the computation is dominated by the term \scivar{a}.
The imaginary part \scivar{f} is wrong, because this term should be 
dominated by the term \scivar{a*r}. Since \scivar{r} is in underflow, it 
is represented by zero, which completely changes the result of the 
expression \scivar{b-a*r}, which is now equal to \scivar{b}.
Therefore, the result is equal to \scivar{1.e-307 / 1.e204}, which 
underflows to zero. 

Finally, we analyze why Scilab's division operator performs 
accurately in this case. Indeed, the formula used by Scilab 
is based on Smith's method and we proved that this method 
fails in this case, when we use double floating point numbers. 
Therefore, we experienced here an unexpected high accuracy.

We performed this particular complex division over several common 
computing systems such as various versions of Scilab, Octave, 
Matlab and FreeMat on various operating systems. The results are presented
in figure \ref{fig-compdiv-weird}. Notice that, on Matlab, 
Octave and FreeMat, the syntax is different and we 
used the expression \scivar{(1.e307 + i * 1.e-307)/(1.e204 + i * 1.e-204)}.

\begin{figure}
\begin{center}
\begin{tabular}{|l|l|l|}
\hline
Scilab v5.2.0 release & Windows 32 bits & 1.000+103 - 1.000-305i \\
Scilab v5.2.0 release & Windows 64 bits & 1.000+103 \\
Scilab v5.2.0 debug   & Windows 32 bits & 1.000+103 \\
Scilab v5.1.1 release & Windows 32 bits & 1.000+103 \\
Scilab v4.1.2 release & Windows 32 bits & 1.000+103 \\
Scilab v5.2.0 release & Linux 32 bits   & 1.000+103 - 1.000-305i \\
Scilab v5.1.1 release & Linux 32 bits   & 1.000+103 - 1.000-305i \\
Octave v3.0.3         & Windows 32 bits & 1.0000e+103 \\
Matlab 2008           & Windows 32 bits & 1.0000e+103 -1.0000e-305i \\
Matlab 2008           & Windows 64 bits & 1.0000e+103 \\
FreeMat v3.6          & Windows 32 bits & 1.0000e+103 -1.0000e-305i \\
\hline
\end{tabular}
\end{center}
\caption{Result of the complex division \scivar{(1.e307 + \%i * 1.e-307)/(1.e204 + \%i * 1.e-204)} on various 
softwares and operating systems.}
\label{fig-compdiv-weird}
\end{figure}

The reason of the discrepancies of the results is the following \cite{MullerEtAl2010,Monniaux2008}. 
The processor being used may offer an internal precision that is wider than the 
precision of the variables of a program. 
Indeed, processors of the IA32 architecture (Intel 386, 486, Pentium etc. and 
compatibles) feature a floating-point unit often known as "x87".
This unit has 80-bit registers in "double extended" format with a 64-bit mantissa and
a 15-bit exponent. The most usual way of generating code for the IA32 is to hold temporaries -
and, in optimized code, program variables - in the x87 registers.
Hence, the final result of the computations depend on how the compiler allocates registers.
Since the double extended format of the x87 unit uses 15 bits for the exponent, 
it can store floating point numbers associated with binary exponents from 
$2^{-16382}\approx 10^{-4932}$ up to $2^{16383}\approx 10^{4931}$,
which is much larger than the exponents from the 64-bits double precision 
floating point numbers (ranging from $2^{-1022}\approx 10^{-308}$ up to $2^{1023}\approx 10^{307})$.
Therefore, the computations performed with the x87 unit are less likely to 
generate underflows and overflows. On the other hand, SSE2 extensions introduced 
one 128-bit packed floating-point data type. This 128-bit data type consists of
two IEEE 64-bit double-precision floating-point values packed into a double
quadword.

Depending on the compilers options used to generate the binary,
the result may use either the x87 unit (with 80-bits registers) or the 
SSE unit. Under Windows 32 bits, Scilab v5.2.0 is compiled with the "/arch:IA32" 
option \cite{CordenKreitzerIntel2009}, which allows Scilab to run on 
older Pentium computers that does not support SSE2. In this situation,
Scilab may use the x87 unit. Under Windows 64 bits, Scilab uses the SSE2 unit so that the result 
is based on double precision floating point numbers only.
Under Linux, Scilab is compiled with gcc \cite{GCCManual2008}, 
where the behavior is driven by the -mfpmath option. The default value of this option for i386 machines 
is to use the 387 floating point co-processor while, for x86\_64 machines, the default 
is to use the SSE instruction set.

\subsection{References}

\index{Smith, Robert}
The 1962 paper by R. Smith \cite{Smith1962} describes the algorithm which is used in 
Scilab. 

\index{Goldberg, David}
Goldberg introduces in \cite{WhatEveryComputerScientist} many 
of the subjects presented in this document, including the problem of the 
complex division. 

An analysis of Hough, cited by Coonen \cite{1667289} and Stewart \cite{214414} 
shows that when the algorithm works, it returns a computed value $\overline{z}$
satisfying
\begin{eqnarray}
|\overline{z} - z| <= eps |z|,
\end{eqnarray}
where $z$ is the exact complex division result and $\epsilon$ is of the same order of magnitude 
as the rounding unit for the arithmetic in question. 

The limits of Smith's method have been analyzed by Stewart's in \cite{214414}.
The paper separates the relative error of the complex numbers and the relative
error made on real and imaginary parts. 
Stewart's algorithm is based on a theorem which states that if $x_1 \ldots x_n$
are $n$ floating point representable numbers, and if their product is also 
a representable floating point number, then the product $\min_{i=1,n}(x_i) . \max_{i=1,n}(x_i)$
is also representable. The algorithm uses that theorem to perform a 
correct computation.

\index{Kahan, William}
\index{Stewart, G. W.}
Stewart's algorithm is superseded by the one by Li et Al \cite{567808}, but 
also by Kahan's \cite{KAHAN1987}, which, from  \cite{1039814}, is the one implemented
in the C99 standard.

\index{Knuth, Donald E.}
Knuth presents in \cite{artcomputerKnuthVol2}
the Smith's method in section 4.2.1, as exercize 16. Knuth gives also 
references \cite{Wynn:1962:AAP} and \cite{DBLP:journals/cacm/Friedland67}.
The 1967 paper by Friedland \cite{DBLP:journals/cacm/Friedland67} describes 
two algorithms to compute the absolute value of a complex number 
$|x+iy| = \sqrt{x^2+y^2}$ and the square root of a 
complex number $\sqrt{x+iy}$.

\index{Muller, Jean-Michel}
Issues related to the use of extended double precision floating point 
numbers are analyzed by Muller et al. in \cite{MullerEtAl2010}. 
In the section 3 of part I, "Floating point formats an Environment", 
the authors analyze the "double rounding" problem which occurs when an 
internal precision is wider than the precision of the variables of a 
program. The typical example is the double-extended format available 
on Intel platforms. Muller et al. show different examples, where the 
result depends on the compiler options and the platform, including an example extracted 
from a paper by Monniaux \cite{Monniaux2008}.

\index{Corden, Martyn}
\index{Kreitzer, David}
Corden and Kreitzer analyse in \cite{CordenKreitzerIntel2009} the 
effect of the Intel compiler floating point options on the numerical results.
The paper focuses on the reproductibility issues which are associated 
with floating point computations. The options which allow to be compliant 
with the IEEE standards for C++ and Fortran are presented.
The effects of optimization options is considered with respect to 
speed and the safety of the transformations that may be done on the 
source code.

The "Intel 64 and IA-32 Architectures Software Developer's Manual. Volume 1: Basic Architecture" 
\cite{Intel64IA32Architecture} is part of a set of documents that describes the architecture
and programming environment of Intel 64 and IA-32 architecture processors. The chapter 8, "Programming 
with the x87 environment" presents the registers and the 
instruction set for this unit. The section 8.1.2, "x87 FPU Data Registers" focuses 
on the floating point registers, which are based on 80-bits and implements 
the double extended-precision floating-point format. 
The chapter 10, "Programming with Streaming SIMD Extensions (SSE)" introduces the 
extensions which were introduced into the IA-32 architecture in
the Pentium III processor family. The chapter 11 introduces the SSE2 extensions.

\index{Monniaux, David}
In \cite{Monniaux2008}, David Monniaux presents issues related to the 
analysis of floating point programs. He emphasizes the difficulty
of defining the semantics of common implementation of floating point numbers,
depending on choices made by the compiler. He gives concrete examples of problems that 
can appear and solutions.


